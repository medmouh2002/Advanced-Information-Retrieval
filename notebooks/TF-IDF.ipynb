{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2eb0ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "31\n",
      "33\n",
      "35\n",
      "37\n",
      "39\n",
      "41\n",
      "43\n",
      "45\n",
      "47\n",
      "49\n",
      "51\n",
      "53\n",
      "55\n",
      "57\n",
      "59\n",
      "61\n",
      "63\n",
      "65\n",
      "67\n",
      "69\n",
      "71\n",
      "73\n",
      "75\n",
      "77\n",
      "79\n",
      "81\n",
      "83\n",
      "85\n",
      "87\n",
      "89\n",
      "91\n",
      "93\n",
      "95\n",
      "97\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    " if (i % 2) != 0:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f906425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "def summ(x, y):\n",
    "    summ = 0\n",
    "    for i in range(x, y+1):\n",
    "        if i % 2 == 0:\n",
    "            summ += i\n",
    "    return summ\n",
    "\n",
    "print(summ(9, 20))\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f571a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 32, 26, 52, 39, 8, 15, 32, 79, 48]\n",
      "79\n",
      "8\n",
      "[8, 15, 26, 32, 32, 39, 41, 48, 52, 79]\n",
      "[79, 52, 48, 41, 39, 32, 32, 26, 15, 8]\n",
      "[32, 32, 41, 39, 26, 8, 15, 48, 52, 79]\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "for i in range(1, 11):\n",
    "    r = random.randint(1, 100)\n",
    "    L.append(r)\n",
    "\n",
    "print(L)\n",
    "\n",
    "print(max(L))\n",
    "print(min(L))\n",
    "\n",
    "L.sort()\n",
    "print(L)\n",
    "\n",
    "L.sort(reverse =True)\n",
    "print(L)\n",
    "\n",
    "random.shuffle(L)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d018847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'd': 4, 'b': 2, 'c': 3}\n",
      "[('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n"
     ]
    }
   ],
   "source": [
    " D = {\n",
    " 'a':1,\n",
    " 'd':4,\n",
    " 'b':2,\n",
    " 'c':3,\n",
    " }\n",
    "    \n",
    "print(D)\n",
    "\n",
    "sortedkeys = sorted(D.items())\n",
    "print(sortedkeys)\n",
    "\n",
    "sortedvalues= \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a16a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b496c183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In information retrieval, tf–idf (also TF*IDF, TFIDF, TF–IDF, or Tf–idf), short for term frequency–inverse document frequency, is a measure of importance of a word to a document in a collection or corpus, adjusted for the fact that some words appear more frequently in general.[1] It was often used as a weighting factor in searches of information retrieval, text mining, and user modeling. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries used tf–idf.[2]Variations of the tf–idf weighting scheme were often used by search engines as a central tool in scoring and ranking a document's relevance given a user query.One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple model.\n"
     ]
    }
   ],
   "source": [
    "TFIDF = \"In information retrieval, tf–idf (also TF*IDF, TFIDF, TF–IDF, or Tf–idf), short for term frequency–inverse document frequency, is a measure of importance of a word to a document in a collection or corpus, adjusted for the fact that some words appear more frequently in general.[1] It was often used as a weighting factor in searches of information retrieval, text mining, and user modeling. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries used tf–idf.[2]Variations of the tf–idf weighting scheme were often used by search engines as a central tool in scoring and ranking a document's relevance given a user query.One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple model.\"\n",
    "print(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd20cc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words is: 131\n"
     ]
    }
   ],
   "source": [
    "count = len(\"In information retrieval, tf–idf (also TF*IDF, TFIDF, TF–IDF, or Tf–idf), short for term frequency–inverse document frequency, is a measure of importance of a word to a document in a collection or corpus, adjusted for the fact that some words appear more frequently in general.[1] It was often used as a weighting factor in searches of information retrieval, text mining, and user modeling. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries used tf–idf.[2]Variations of the tf–idf weighting scheme were often used by search engines as a central tool in scoring and ranking a document's relevance given a user query.One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple model.\".split())\n",
    "print(\"Number of words is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da9fcce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weighting', 'often', 'to', '(also', 'showed', 'user', 'survey', 'simplest', 'general.[1]', 'central', 'model.', 'some', 'functions', \"document's\", 'many', 'It', 'recommender', 'search', 'this', 'modeling.', 'a', 'variants', 'term;', 'short', 'tool', 'frequency,', 'as', 'and', 'simple', 'ranking', 'sophisticated', 'summing', 'text', 'term', 'that', 'fact', 'tf–idf.[2]Variations', 'given', 'is', 'importance', 'frequently', 'word', 'scheme', 'document', 'A', 'used', 'information', '2015', 'digital', 'mining,', 'In', 'were', 'appear', 'libraries', 'measure', 'TF*IDF,', 'computed', 'retrieval,', 'Tf–idf),', 'collection', 'searches', 'words', 'conducted', 'engines', 'in', 'more', 'frequency–inverse', 'query', 'by', 'each', 'corpus,', 'scoring', 'was', 'TFIDF,', 'systems', 'or', 'the', 'adjusted', 'query.One', 'factor', 'relevance', 'text-based', 'are', 'of', 'tf–idf', 'for', '83%', 'TF–IDF,'}\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "string = \"In information retrieval, tf–idf (also TF*IDF, TFIDF, TF–IDF, or Tf–idf), short for term frequency–inverse document frequency, is a measure of importance of a word to a document in a collection or corpus, adjusted for the fact that some words appear more frequently in general.[1] It was often used as a weighting factor in searches of information retrieval, text mining, and user modeling. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries used tf–idf.[2]Variations of the tf–idf weighting scheme were often used by search engines as a central tool in scoring and ranking a document's relevance given a user query.One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple model.\"\n",
    "\n",
    "unique_words = set(string.split())\n",
    "print(unique_words)\n",
    "\n",
    "length = len(unique_words)\n",
    "print(length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9163bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 8)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "  \n",
    "split = string.split() \n",
    "Counter = Counter(split) \n",
    "most_occur = Counter.most_common(1) \n",
    "  \n",
    "print(most_occur) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9b3019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In information retrieval, tfâ€“idf (also TF*IDF, TFIDF, TFâ€“IDF, or Tfâ€“idf), short for term frequencyâ€“inverse document frequency, is a measure of importance of a word to a document in a collection or corpus, adjusted for the fact that some words appear more frequently in general.[1] It was often used as a weighting factor in searches of information retrieval, text mining, and user modeling. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries used tfâ€“idf.[2]Variations of the tfâ€“idf weighting scheme were often used by search engines as a central tool in scoring and ranking a document's relevance given a user query.One of the simplest ranking functions is computed by summing the tfâ€“idf for each query term; many more sophisticated ranking functions are variants of this simple model.\"\n",
      "Number of words is: 131\n",
      "{'adjusted', 'user', 'word', 'Tfâ€“idf),', 'given', 'and', 'A', 'weighting', 'functions', 'is', 'a', 'are', 'engines', 'relevance', 'fact', 'modeling.', 'were', 'term', 'In', 'more', 'tool', 'central', 'sophisticated', 'simplest', 'to', 'as', 'corpus,', 'TFIDF,', 'term;', 'by', 'tfâ€“idf', 'words', 'collection', 'systems', 'survey', 'short', 'this', 'general.[1]', 'for', 'text', 'scheme', 'ranking', 'TF*IDF,', 'mining,', 'TFâ€“IDF,', 'some', 'of', '(also', 'query', 'digital', 'model.\"', 'showed', \"document's\", 'simple', 'each', 'conducted', 'retrieval,', 'tfâ€“idf.[2]Variations', 'used', 'text-based', '2015', 'computed', 'It', 'information', 'frequently', 'libraries', 'importance', 'query.One', '83%', 'document', 'appear', 'many', 'variants', 'frequency,', 'that', 'scoring', 'often', 'search', 'or', 'in', 'the', 'recommender', 'factor', 'was', 'frequencyâ€“inverse', 'searches', 'measure', 'summing'}\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"C:\\\\Users\\pc\\Desktop\\TFIDF.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)\n",
    "\n",
    "\n",
    "count = len(content.split())\n",
    "print(\"Number of words is:\", count)\n",
    "\n",
    "unique_words = set(content.split())\n",
    "print(unique_words)\n",
    "\n",
    "length = len(unique_words)\n",
    "print(length) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bfea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 8)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "  \n",
    "split = content.split() \n",
    "Counter = Counter(split) \n",
    "most_occur = Counter.most_common(1) \n",
    "  \n",
    "print(most_occur) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231060b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f6525c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent words are:\n",
      ",: 9\n",
      "“: 7\n",
      "idf: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "words = nltk.word_tokenize(content)\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "res = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "word_freq = Counter(res)\n",
    "\n",
    "# Print the most common words\n",
    "print(\"The most frequent words are:\")\n",
    "for word, freq in word_freq.most_common(3):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a145e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le TF-IDF (de l'anglais term frequency-inverse document frequency) est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes. Cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document, relativement à une collection ou un corpus. Le poids augmente proportionnellement au nombre d'occurrences du mot dans le document. Il varie également en fonction de la répartition du mot dans le corpus. Des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur.\n"
     ]
    }
   ],
   "source": [
    "TFIDF = \"Le TF-IDF (de l'anglais term frequency-inverse document frequency) est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes. Cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document, relativement à une collection ou un corpus. Le poids augmente proportionnellement au nombre d'occurrences du mot dans le document. Il varie également en fonction de la répartition du mot dans le corpus. Des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur.\"\n",
    "print(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6da389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words is: 98\n"
     ]
    }
   ],
   "source": [
    "count = len(\"Le TF-IDF (de l'anglais term frequency-inverse document frequency) est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes. Cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document, relativement à une collection ou un corpus. Le poids augmente proportionnellement au nombre d'occurrences du mot dans le document. Il varie également en fonction de la répartition du mot dans le corpus. Des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur.\".split())\n",
    "print(\"Number of words is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff3eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en', 'à', 'souvent', 'textes.', 'recherche', 'frequency-inverse', 'pondération', 'utilisée', 'mesure', \"d'occurrences\", 'document.', 'pour', 'de', 'méthode', 'augmente', 'Des', 'utilisées', 'critères', 'poids', 'un', \"d'information\", 'Cette', 'apprécier', 'corpus.', 'permet', \"l'utilisateur.\", 'varie', 'nombre', 'du', 'mot', \"l'anglais\", 'également', 'au', 'statistique', 'originale', 'répartition', \"d'un\", 'frequency)', 'fouille', 'la', 'fonction', 'Le', 'formule', 'document,', 'dans', 'variantes', 'des', 'term', 'est', 'pertinence', \"l'importance\", 'contenu', \"d'évaluer\", '(de', 'terme', 'et', 'le', 'particulier', 'relativement', 'ou', 'collection', 'proportionnellement', 'moteurs', 'TF-IDF', 'sont', 'une', 'document', 'Il'}\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "string = \"Le TF-IDF (de l'anglais term frequency-inverse document frequency) est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes. Cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document, relativement à une collection ou un corpus. Le poids augmente proportionnellement au nombre d'occurrences du mot dans le document. Il varie également en fonction de la répartition du mot dans le corpus. Des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur.\"\n",
    "\n",
    "unique_words = set(string.split())\n",
    "print(unique_words)\n",
    "\n",
    "length = len(unique_words)\n",
    "print(length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9a6664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('de', 7)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "  \n",
    "split = string.split() \n",
    "Counter = Counter(split) \n",
    "most_occur = Counter.most_common(1) \n",
    "  \n",
    "print(most_occur) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250d6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le TF-IDF (de l'anglais term frequency-inverse document frequency) est une mÃ©thode de pondÃ©ration souvent utilisÃ©e en recherche d'information et en particulier dans la fouille de textes. Cette mesure statistique permet d'Ã©valuer l'importance d'un terme contenu dans un document, relativement Ã  une collection ou un corpus. Le poids augmente proportionnellement au nombre d'occurrences du mot dans le document. Il varie Ã©galement en fonction de la rÃ©partition du mot dans le corpus. Des variantes de la formule originale sont souvent utilisÃ©es dans des moteurs de recherche pour apprÃ©cier la pertinence d'un document en fonction des critÃ¨res de recherche de l'utilisateur.\n",
      "Number of words is: 98\n",
      "{'en', \"d'occurrences\", 'souvent', 'textes.', 'recherche', 'frequency-inverse', 'mesure', \"d'Ã©valuer\", 'document.', 'pour', \"l'utilisateur.\", 'de', 'pondÃ©ration', 'augmente', 'Des', 'poids', 'un', \"d'information\", 'Cette', 'corpus.', 'permet', 'varie', 'nombre', 'du', 'mot', \"l'anglais\", 'originale', 'au', 'statistique', 'moteurs', \"d'un\", 'frequency)', 'fouille', 'la', 'utilisÃ©e', 'Le', 'fonction', 'document,', 'dans', 'variantes', 'formule', 'des', 'Ã', 'term', 'est', 'pertinence', 'mÃ©thode', \"l'importance\", 'contenu', 'rÃ©partition', 'apprÃ©cier', '(de', 'terme', 'et', 'le', 'particulier', 'relativement', 'ou', 'collection', 'critÃ¨res', 'proportionnellement', 'TF-IDF', 'Ã©galement', 'sont', 'une', 'utilisÃ©es', 'document', 'Il'}\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"C:\\\\Users\\pc\\Desktop\\TFIDF2.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)\n",
    "\n",
    "\n",
    "count = len(content.split())\n",
    "print(\"Number of words is:\", count)\n",
    "\n",
    "unique_words = set(content.split())\n",
    "print(unique_words)\n",
    "\n",
    "length = len(unique_words)\n",
    "print(length) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d0115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('de', 7)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "  \n",
    "split = content.split() \n",
    "Counter = Counter(split) \n",
    "most_occur = Counter.most_common(1) \n",
    "  \n",
    "print(most_occur) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26a9340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f81d26f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent words are:\n",
      ".: 5\n",
      "document: 4\n",
      "recherche: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "words = nltk.word_tokenize(content)\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "res = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "word_freq = Counter(res)\n",
    "\n",
    "# Print the most common words\n",
    "print(\"The most frequent words are:\")\n",
    "for word, freq in word_freq.most_common(3):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c79d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
